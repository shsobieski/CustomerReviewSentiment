{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Sentiment Classifier\n",
    "\n",
    "## Data Cleaning and EDA\n",
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:48.371904Z",
     "start_time": "2020-06-26T00:20:48.354720Z"
    }
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['[WinError 127] The specified procedure could not be found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0706295daaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#from sklearn.metrics import (classification_report,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                              \u001b[1;31m#plot_confusion_matrix)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;31m# load the XGBoost library globally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;34m'libgomp.so for UNIX-like OSes)\\n'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: XGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['[WinError 127] The specified procedure could not be found']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "#from sklearn.metrics import (classification_report, \n",
    "                             #plot_confusion_matrix)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "%matplotlib inline\n",
    "\n",
    "%run -i \"clean_lemmatize_token.py\"\n",
    "%run -i \"report.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from data.world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.195119Z",
     "start_time": "2020-06-26T00:20:48.374482Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://query.data.world/s/zbehvjkmiewbkln44rae6iphum4v3g', \n",
    "                 encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.209930Z",
     "start_time": "2020-06-26T00:20:49.198395Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df.rename(columns = {'emotion_in_tweet_is_directed_at':\n",
    "                        'brand_product',\n",
    "                        'is_there_an_emotion_directed_at_a_brand_or_product':\n",
    "                        'sentiment'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explored data set with info() method. 1 NaN value present in tweet_text column and ~6,000 in brand_product column. Will need to address prior to modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.220436Z",
     "start_time": "2020-06-26T00:20:49.212597Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaN tweet_text from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.241004Z",
     "start_time": "2020-06-26T00:20:49.222923Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['tweet_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.252465Z",
     "start_time": "2020-06-26T00:20:49.245882Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(inplace= True, index=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "Explored Sentiment category. Most tweets are marked as having No emotion which will not help initial binary classification model. Most data in data set will only be usuable when model is built to take into account neutral sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.269991Z",
     "start_time": "2020-06-26T00:20:49.255207Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.292120Z",
     "start_time": "2020-06-26T00:20:49.275962Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['sentiment'] == \"I can't tell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.304462Z",
     "start_time": "2020-06-26T00:20:49.297163Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummied Sentiment Column to help with visulizations to compare sentiment across brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.322018Z",
     "start_time": "2020-06-26T00:20:49.306854Z"
    }
   },
   "outputs": [],
   "source": [
    "df1=pd.get_dummies(df['sentiment'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.342671Z",
     "start_time": "2020-06-26T00:20:49.325013Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummied=df.join(df1).drop(columns='sentiment')\n",
    "df_dummied.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made visualization to explore distribution of sentiment across brand/product. Will combine Apple and Google products to further explore distribution. Sentiment is overwhelmingly positive across all products and most sentiment data is logged for Apple products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.696179Z",
     "start_time": "2020-06-26T00:20:49.345503Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummied.groupby('brand_product').sum().plot(kind='barh', \n",
    "                                               figsize=(10,7))\n",
    "plt.title('Sentiment Analysis by Brand/Product', size=20)\n",
    "plt.ylabel('Brand/Product', size=15)\n",
    "plt.xlabel('# of Instances', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made below visualization to explore the missing brand_product classifications for each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.890636Z",
     "start_time": "2020-06-26T00:20:49.698365Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('sentiment').count().plot(kind='barh',\n",
    "                                     figsize=(10,5))\n",
    "plt.title('Sentiment Distribution', size=20)\n",
    "plt.ylabel('Sentiment', size=15)\n",
    "plt.xlabel('# of Instances',size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usable data (Positive or Negative sentiment) for baseline first model is 39.02%. Will be necessary to eventually build a multiclass classifier with No Emotion classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.900977Z",
     "start_time": "2020-06-26T00:20:49.892684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usable_data=round(len(df.loc[(df['sentiment'] == 'Positive emotion') | \n",
    "                             (df['sentiment'] == 'Negative emotion')])/len(df) * 100,2)\n",
    "print('Percentage of Data with either Positive or Negative Sentiment: {}%'.format(usable_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Apple and Google product names together to explore further visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:49.921590Z",
     "start_time": "2020-06-26T00:20:49.903028Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dummied['brand_product']=df_dummied['brand_product'].replace(to_replace = ['iPad','Apple',\n",
    "                                                                                    'iPad or iPhone App','iPhone',\n",
    "                                                                                    'Other Apple product or service'],value='apple_product')\n",
    "df_dummied['brand_product'] = df_dummied['brand_product'].replace(['Google',\n",
    "                                                                        'Other Google product or service',\n",
    "                                                                        'Android App', 'Android'],'android_product')\n",
    "df_dummied['brand_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Brand_product columns to show difference in amount of information for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:50.151425Z",
     "start_time": "2020-06-26T00:20:49.924286Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummied.groupby('brand_product').sum().plot(kind='barh', figsize=(10,4))\n",
    "plt.title('Sentiment Analysis by Brand/Product Combined', size=20)\n",
    "plt.ylabel('Brand/Product', size=15)\n",
    "plt.xlabel('# of Instances', size=15)\n",
    "plt.yticks(np.arange(2),['Google Product','Apple Product'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made a copy of the data frame to further explore EDA options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:50.162524Z",
     "start_time": "2020-06-26T00:20:50.153597Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eda = df\n",
    "df_eda.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used an alternative version of our clean_lemmatize_token function to preprocess data for additional EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:50.170752Z",
     "start_time": "2020-06-26T00:20:50.164701Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_lemmatize_token_alt(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned = tweet.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    tokenized = word_tokenize(cleaned)\n",
    "    filtered = [w for w in tokenized if not w in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    for word in filtered:\n",
    "        lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    to_remove = ['rt','mention','sxsw','link']\n",
    "    lemmatized = [w for w in lemmatized if w not in to_remove]\n",
    "    #lemmatized = ' '.join(lemmatized)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:20:54.213668Z",
     "start_time": "2020-06-26T00:20:50.172835Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eda['tweet_text'] = df_eda['tweet_text'].map(lambda x: clean_lemmatize_token_alt(x))\n",
    "df_eda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:22:06.117300Z",
     "start_time": "2020-06-26T00:22:06.110737Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eda['brand_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:33:41.111343Z",
     "start_time": "2020-06-26T00:33:41.083219Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pos_apple_mobile = df_eda.loc[(df_eda['sentiment'] == 'Positive emotion') & (df_eda['brand_product'] == 'iPad') \n",
    "                                 | (df_eda['brand_product'] == 'iPhone') | (df_eda['brand_product'] == 'iPad or iPhone App')]\n",
    "df_neg_apple_mobile = df_eda.loc[(df_eda['sentiment'] == 'Negative emotion') & (df_eda['brand_product'] == 'iPad') \n",
    "                                 | (df_eda['brand_product'] == 'iPhone') | (df_eda['brand_product'] == 'iPad or iPhone App')]\n",
    "df_pos_android_mobile = df_eda.loc[(df_eda['sentiment'] == 'Positive emotion') & (df_eda['brand_product'] == 'Other Google Product or Service') \n",
    "                                 | (df_eda['brand_product'] == 'Android App') | (df_eda['brand_product'] == 'Android')]\n",
    "df_neg_android_mobile = df_eda.loc[(df_eda['sentiment'] == 'Negative emotion') & (df_eda['brand_product'] == 'Other Google Product or Service') \n",
    "                                 | (df_eda['brand_product'] == 'Android App') | (df_eda['brand_product'] == 'Android')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:35:36.730342Z",
     "start_time": "2020-06-26T00:35:36.726388Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_apple_mobile_tweet_list = df_pos_apple_mobile['tweet_text']\n",
    "neg_apple_mobile_tweet_list = df_neg_apple_mobile['tweet_text']\n",
    "pos_android_mobile_list = df_pos_android_mobile['tweet_text']\n",
    "neg_android_mobile_list = df_neg_android_mobile['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:37:24.618913Z",
     "start_time": "2020-06-26T00:37:24.613081Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_apple_mobile_concat = []\n",
    "neg_apple_mobile_concat = []\n",
    "pos_android_mobile_concat = []\n",
    "neg_android_mobile_concat = []\n",
    "\n",
    "for tweet in pos_apple_mobile_tweet_list:\n",
    "    pos_apple_mobile_concat += tweet\n",
    "for tweet in neg_apple_mobile_tweet_list:\n",
    "    neg_apple_mobile_concat += tweet\n",
    "for tweet in pos_android_mobile_list:\n",
    "    pos_android_mobile_concat += tweet  \n",
    "for tweet in neg_android_mobile_list:\n",
    "    neg_android_mobile_concat += tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:44:36.248140Z",
     "start_time": "2020-06-26T00:44:36.244232Z"
    }
   },
   "outputs": [],
   "source": [
    "len(pos_apple_mobile_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:38:42.597188Z",
     "start_time": "2020-06-26T00:38:42.593960Z"
    }
   },
   "outputs": [],
   "source": [
    "mobile_concat_list = [pos_apple_mobile_concat, neg_apple_mobile_concat, pos_android_mobile_concat,\n",
    "                      neg_android_mobile_concat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:45:17.024984Z",
     "start_time": "2020-06-26T00:45:16.875636Z"
    }
   },
   "outputs": [],
   "source": [
    "mobile_tweets_scored_list = []\n",
    "for mobile_list in mobile_concat_list:\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    tweet_finder = BigramCollocationFinder.from_words(mobile_list)\n",
    "    tweets_scored = tweet_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    mobile_tweets_scored_list.append(tweets_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:46:02.573868Z",
     "start_time": "2020-06-26T00:46:01.595110Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mobile_graph1 = pd.DataFrame(mobile_tweets_scored_list[0][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_mobile_graph2 = pd.DataFrame(mobile_tweets_scored_list[1][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_mobile_graph3 = pd.DataFrame(mobile_tweets_scored_list[2][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_mobile_graph4 = pd.DataFrame(mobile_tweets_scored_list[3][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_figheight(17)\n",
    "fig.set_figwidth(23)\n",
    "axs[0,0].title.set_text('Positive Apple Mobile Tweets Bigrams')\n",
    "axs[0,1].title.set_text('Negative Apple Mobile Tweets Bigrams')\n",
    "axs[1,0].title.set_text('Positive Android Mobile Tweets Bigrams')\n",
    "axs[1,1].title.set_text('Negative Android Mobile Tweets Bigrams')\n",
    "sns.barplot(data=df_mobile_graph1, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,0])\n",
    "sns.barplot(data=df_mobile_graph2, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,1])\n",
    "sns.barplot(data=df_mobile_graph3, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,0])\n",
    "sns.barplot(data=df_mobile_graph4, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined all Apple products and all Google products together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T20:51:22.215610Z",
     "start_time": "2020-06-25T20:51:22.201706Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eda['brand_product']=df_eda['brand_product'].replace(to_replace = ['iPad','Apple',\n",
    "                                                                                    'iPad or iPhone App','iPhone',\n",
    "                                                                                    'Other Apple product or service'],value='apple_product')\n",
    "df_eda['brand_product'] = df_eda['brand_product'].replace(['Google',\n",
    "                                                                        'Other Google product or service',\n",
    "                                                                        'Android App', 'Android'],'android_product')\n",
    "df_eda['brand_product'].value_counts(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created new data frames based on different brands and sentiments to plot bigrams of most common word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T20:53:13.010120Z",
     "start_time": "2020-06-25T20:53:12.977825Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pos = df_eda.loc[df_eda['sentiment'] == 'Positive emotion']\n",
    "df_neg = df_eda.loc[df_eda['sentiment'] == 'Negative emotion']\n",
    "df_none = df_eda.loc[df_eda['sentiment'] == 'No emotion toward brand or product']\n",
    "df_apple = df_eda.loc[df_eda['brand_product'] == 'apple_product']\n",
    "df_google = df_eda.loc[df_eda['brand_product'] == 'android_product']\n",
    "df_pos_apple = df_eda.loc[(df_eda['brand_product'] == 'apple_product') & (df_eda['sentiment'] == 'Positive emotion')]\n",
    "df_neg_apple = df_eda.loc[(df_eda['brand_product'] == 'apple_product') & (df_eda['sentiment'] == 'Negative emotion')]\n",
    "df_none_apple = df_eda.loc[(df_eda['brand_product'] == 'apple_product') & (df_eda['sentiment'] == 'No emotion toward brand or product')]\n",
    "df_pos_google = df_eda.loc[(df_eda['brand_product'] == 'android_product') & (df_eda['sentiment'] == 'Positive emotion')]\n",
    "df_neg_google = df_eda.loc[(df_eda['brand_product'] == 'android_product') & (df_eda['sentiment'] == 'Negative emotion')]\n",
    "df_none_google = df_eda.loc[(df_eda['brand_product'] == 'android_product') & (df_eda['sentiment'] == 'No emotion toward brand or product')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T20:55:13.081523Z",
     "start_time": "2020-06-25T20:55:13.076280Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_list = df_eda['tweet_text']\n",
    "pos_tweet_list = df_pos['tweet_text']\n",
    "neg_tweet_list = df_neg['tweet_text']\n",
    "none_tweet_list = df_none['tweet_text']\n",
    "apple_tweet_list = df_apple['tweet_text']\n",
    "apple_pos_tweet_list = df_pos_apple['tweet_text']\n",
    "apple_neg_tweet_list = df_neg_apple['tweet_text']\n",
    "apple_none_tweet_list = df_none_apple['tweet_text']\n",
    "google_tweet_list = df_google['tweet_text']\n",
    "google_pos_tweet_list = df_pos_google['tweet_text']\n",
    "google_neg_tweet_list = df_neg_google['tweet_text']\n",
    "google_none_tweet_list = df_none_google['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T20:55:36.436864Z",
     "start_time": "2020-06-25T20:55:36.420016Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_concat = []\n",
    "pos_tweet_concat = []\n",
    "neg_tweet_concat = []\n",
    "none_tweet_concat = []\n",
    "apple_tweet_concat = []\n",
    "apple_pos_tweet_concat = []\n",
    "apple_neg_tweet_concat = []\n",
    "apple_none_tweet_concat = []\n",
    "google_tweet_concat = []\n",
    "google_pos_tweet_concat = []\n",
    "google_neg_tweet_concat = []\n",
    "google_none_tweet_concat = []\n",
    "\n",
    "for tweet in tweet_list:\n",
    "    tweet_concat += tweet\n",
    "for tweet in pos_tweet_list:\n",
    "    pos_tweet_concat += tweet\n",
    "for tweet in neg_tweet_list:\n",
    "    neg_tweet_concat += tweet  \n",
    "for tweet in none_tweet_list:\n",
    "    none_tweet_concat += tweet\n",
    "\n",
    "for tweet in apple_tweet_list:\n",
    "    apple_tweet_concat += tweet\n",
    "for tweet in apple_pos_tweet_list:\n",
    "    apple_pos_tweet_concat += tweet\n",
    "for tweet in apple_neg_tweet_list:\n",
    "    apple_neg_tweet_concat += tweet  \n",
    "for tweet in apple_none_tweet_list:\n",
    "    apple_none_tweet_concat += tweet\n",
    "\n",
    "for tweet in google_tweet_list:\n",
    "    google_tweet_concat += tweet\n",
    "for tweet in google_pos_tweet_list:\n",
    "    google_pos_tweet_concat += tweet\n",
    "for tweet in google_neg_tweet_list:\n",
    "    google_neg_tweet_concat += tweet  \n",
    "for tweet in google_none_tweet_list:\n",
    "    google_none_tweet_concat += tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T20:55:55.426810Z",
     "start_time": "2020-06-25T20:55:55.423621Z"
    }
   },
   "outputs": [],
   "source": [
    "concat_list=[tweet_concat,\n",
    "pos_tweet_concat,\n",
    "neg_tweet_concat,\n",
    "none_tweet_concat,\n",
    "apple_tweet_concat,\n",
    "apple_pos_tweet_concat,\n",
    "apple_neg_tweet_concat,\n",
    "apple_none_tweet_concat,\n",
    "google_tweet_concat,\n",
    "google_pos_tweet_concat,\n",
    "google_neg_tweet_concat,\n",
    "google_none_tweet_concat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used a for loop to collect Raw Frequency Scores for each subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T20:56:40.555357Z",
     "start_time": "2020-06-25T20:56:39.278994Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_scored_list = []\n",
    "for list in concat_list:\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    tweet_finder = BigramCollocationFinder.from_words(list)\n",
    "    tweets_scored = tweet_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    tweets_scored_list.append(tweets_scored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted the All Tweets Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T21:42:02.468864Z",
     "start_time": "2020-06-25T21:42:01.470933Z"
    }
   },
   "outputs": [],
   "source": [
    "df_graph1 = pd.DataFrame(tweets_scored_list[0][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph2 = pd.DataFrame(tweets_scored_list[1][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph3 = pd.DataFrame(tweets_scored_list[2][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph4 = pd.DataFrame(tweets_scored_list[3][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_figheight(17)\n",
    "fig.set_figwidth(23)\n",
    "axs[0,0].title.set_text('All Tweets Bigrams')\n",
    "axs[0,1].title.set_text('All Positive Tweets Bigrams')\n",
    "axs[1,0].title.set_text('All Negative Tweets Bigrams')\n",
    "axs[1,1].title.set_text('All No Emotion Tweets Bigrams')\n",
    "sns.barplot(data=df_graph1, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,0])\n",
    "sns.barplot(data=df_graph2, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,1])\n",
    "sns.barplot(data=df_graph3, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,0])\n",
    "sns.barplot(data=df_graph4, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted the Apple Tweets Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T21:44:01.262840Z",
     "start_time": "2020-06-25T21:44:00.242030Z"
    }
   },
   "outputs": [],
   "source": [
    "df_graph5 = pd.DataFrame(tweets_scored_list[4][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph6 = pd.DataFrame(tweets_scored_list[5][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph7 = pd.DataFrame(tweets_scored_list[6][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph8 = pd.DataFrame(tweets_scored_list[7][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_figheight(17)\n",
    "fig.set_figwidth(23)\n",
    "axs[0,0].title.set_text('All Apple Tweets Bigrams')\n",
    "axs[0,1].title.set_text('All Positive Apple Tweets Bigrams')\n",
    "axs[1,0].title.set_text('All Negative Apple Tweets Bigrams')\n",
    "axs[1,1].title.set_text('All No Emotion Apple Tweets Bigrams')\n",
    "sns.barplot(data=df_graph5, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,0])\n",
    "sns.barplot(data=df_graph6, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,1])\n",
    "sns.barplot(data=df_graph7, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,0])\n",
    "sns.barplot(data=df_graph8, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted the Google Tweets Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T21:44:37.033902Z",
     "start_time": "2020-06-25T21:44:36.048862Z"
    }
   },
   "outputs": [],
   "source": [
    "df_graph9 = pd.DataFrame(tweets_scored_list[8][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph10 = pd.DataFrame(tweets_scored_list[9][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph11 = pd.DataFrame(tweets_scored_list[10][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "df_graph12 = pd.DataFrame(tweets_scored_list[11][:10], columns = ['Bigram','Raw_Frequency_Score'])\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_figheight(17)\n",
    "fig.set_figwidth(23)\n",
    "axs[0,0].title.set_text('All Google Tweets Bigrams')\n",
    "axs[0,1].title.set_text('All Positive Google Tweets Bigrams')\n",
    "axs[1,0].title.set_text('All Negative Google Tweets Bigrams')\n",
    "axs[1,1].title.set_text('All No Emotion Google Tweets Bigrams')\n",
    "sns.barplot(data=df_graph9, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,0])\n",
    "sns.barplot(data=df_graph10, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[0,1])\n",
    "sns.barplot(data=df_graph11, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,0])\n",
    "sns.barplot(data=df_graph12, y='Bigram',x='Raw_Frequency_Score', orient='h', ax = axs[1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Tweets\n",
    "Clean, lemmatize, and format data for vectorization and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_text'] = df['tweet_text'].map(clean_lemmatize_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary classification model\n",
    "Split the DataFrame to take only binary options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = df[(df['sentiment'] == 'Negative emotion')|\n",
    "            (df['sentiment'] == 'Positive emotion')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(binary['tweet_text'])\n",
    "Y = binary['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver= 'lbfgs', \n",
    "                            multi_class = 'auto', \n",
    "                            max_iter = 400, \n",
    "                            class_weight = 'balanced')\n",
    "report(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tree = RandomForestClassifier()\n",
    "report(rand_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Support Vector Machine Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:11:51.997337Z",
     "start_time": "2020-06-25T23:11:51.987157Z"
    }
   },
   "outputs": [],
   "source": [
    "df_modeling = df_eda.loc[(df_eda['sentiment'] == 'Positive emotion') | \n",
    "                         (df_eda['sentiment'] == 'Negative emotion')]\n",
    "df_modeling['sentiment'] = df_modeling['sentiment'].replace({'Positive emotion':1,'Negative emotion':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:15:31.434125Z",
     "start_time": "2020-06-25T23:15:31.420027Z"
    }
   },
   "outputs": [],
   "source": [
    "df_modeling['tweet_text'] = df_modeling['tweet_text'].map(lambda x: ' '.join(x))\n",
    "df_modeling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:17:37.324290Z",
     "start_time": "2020-06-25T23:17:37.321172Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_idfvectorizer = TfidfVectorizer(max_features = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:17:58.930380Z",
     "start_time": "2020-06-25T23:17:58.927466Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_modeling['tweet_text']\n",
    "y = df_modeling['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:18:09.718327Z",
     "start_time": "2020-06-25T23:18:09.712334Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:18:26.679376Z",
     "start_time": "2020-06-25T23:18:26.574374Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_idfvectorizer.fit(X)\n",
    "X_train_tfidf = tf_idfvectorizer.transform(X_train)\n",
    "X_test_tfidf = tf_idfvectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:24:36.369519Z",
     "start_time": "2020-06-25T23:24:35.773969Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='linear', class_weight='balanced')\n",
    "svm_clf.fit(X_train_tfidf,y_train)\n",
    "y_test_preds = svm_clf.predict(X_test_tfidf)\n",
    "y_train_preds = svm_clf.predict(X_train_tfidf)\n",
    "print(classification_report(y_test, y_test_preds))\n",
    "print(confusion_matrix(y_test, y_test_preds))\n",
    "print(\"Test SVM Accuracy Score -> \",accuracy_score(y_test, y_test_preds)*100)\n",
    "print(\"Training SVM Accuracy Score -> \",accuracy_score(y_train, y_train_preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:27:13.036668Z",
     "start_time": "2020-06-25T23:27:13.032369Z"
    }
   },
   "outputs": [],
   "source": [
    "params_svc = {'C': [0.1, 1, 10, 100], 'gamma':[1,0.1,0.01,0.001]}\n",
    "estimator_svc = SVC(kernel='linear',\n",
    "                    class_weight='balanced')\n",
    "grid_search_svc = GridSearchCV(estimator=estimator_svc, \n",
    "                              param_grid=params_svc,\n",
    "                              scoring = 'accuracy',\n",
    "                              n_jobs = -1,\n",
    "                              cv = 10,\n",
    "                              verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:28:25.276030Z",
     "start_time": "2020-06-25T23:27:48.470525Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_svc.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:28:25.861394Z",
     "start_time": "2020-06-25T23:28:25.856942Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:30:21.286532Z",
     "start_time": "2020-06-25T23:30:20.570897Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='linear', class_weight='balanced', C = 10, gamma= 1)\n",
    "svm_clf.fit(X_train_tfidf,y_train)\n",
    "y_test_preds = svm_clf.predict(X_test_tfidf)\n",
    "y_train_preds = svm_clf.predict(X_train_tfidf)\n",
    "print(classification_report(y_test, y_test_preds))\n",
    "print(confusion_matrix(y_test, y_test_preds))\n",
    "print(\"Test SVM Accuracy Score -> \",accuracy_score(y_test, y_test_preds)*100)\n",
    "print(\"Training SVM Accuracy Score -> \",accuracy_score(y_train, y_train_preds)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:32:35.817105Z",
     "start_time": "2020-06-25T23:32:35.318813Z"
    }
   },
   "outputs": [],
   "source": [
    "xgbc_clf = XGBClassifier()\n",
    "xgbc_clf.fit(X_train_tfidf, y_train)\n",
    "y_test_preds = xgbc_clf.predict(X_test_tfidf)\n",
    "y_train_preds = xgbc_clf.predict(X_train_tfidf)\n",
    "print(classification_report(y_test, y_test_preds))\n",
    "print(confusion_matrix(y_test, y_test_preds))\n",
    "print(\"Test SVM Accuracy Score -> \",accuracy_score(y_test, y_test_preds)*100)\n",
    "print(\"Training SVM Accuracy Score -> \",accuracy_score(y_train, y_train_preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T23:49:46.792256Z",
     "start_time": "2020-06-25T23:48:59.357543Z"
    }
   },
   "outputs": [],
   "source": [
    "train_test_difference = []\n",
    "train_score = []\n",
    "test_score = []\n",
    "for i in np.arange(0.01, 1.01, 0.01):\n",
    "    xgbc_clf = XGBClassifier(scale_pos_weight=i)\n",
    "    xgbc_clf.fit(X_train_tfidf, y_train)\n",
    "    y_test_preds = xgbc_clf.predict(X_test_tfidf)\n",
    "    y_train_preds = xgbc_clf.predict(X_train_tfidf)\n",
    "    train_test_difference.append((accuracy_score(y_train, y_train_preds) * 100) - \n",
    "                                 (accuracy_score(y_test, y_test_preds)*100))\n",
    "    train_score.append(accuracy_score(y_train, y_train_preds) * 100)\n",
    "    test_score.append(accuracy_score(y_test, y_test_preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:00:56.143961Z",
     "start_time": "2020-06-26T00:00:56.118315Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame([np.arange(0.01, 1.01, 0.01), train_test_difference, train_score, test_score]).T\n",
    "df_results=df_results.rename(columns = {0:'pos_scale_weight',1:'train_test_difference', 2:'train_score', 3:'test_score'})\n",
    "df_results.sort_values(['train_test_difference','test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:01:22.886240Z",
     "start_time": "2020-06-26T00:01:22.388340Z"
    }
   },
   "outputs": [],
   "source": [
    "xgbc_clf = XGBClassifier(scale_pos_weight=.96)\n",
    "xgbc_clf.fit(X_train_tfidf, y_train)\n",
    "y_test_preds = xgbc_clf.predict(X_test_tfidf)\n",
    "y_train_preds = xgbc_clf.predict(X_train_tfidf)\n",
    "print(classification_report(y_test, y_test_preds))\n",
    "print(confusion_matrix(y_test, y_test_preds))\n",
    "print(\"Test SVM Accuracy Score -> \",accuracy_score(y_test, y_test_preds)*100)\n",
    "print(\"Training SVM Accuracy Score -> \",accuracy_score(y_train, y_train_preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:10:27.912947Z",
     "start_time": "2020-06-26T00:10:27.908329Z"
    }
   },
   "outputs": [],
   "source": [
    "params_xgboost = {'max_depth': range(2,10,1),\n",
    "         'n_estimators': range(60,220,40),\n",
    "         'learning_rate': [0.1, 0.01, 0.05]}\n",
    "estimator_xgboost = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    n_jobs=-1,\n",
    "    seed=42, \n",
    "    pos_scale_weight = .96\n",
    ")\n",
    "grid_search_xgboost = GridSearchCV(\n",
    "    estimator=estimator_xgboost,\n",
    "    param_grid=params_xgboost,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = -1,\n",
    "    cv = 10,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:14:09.969944Z",
     "start_time": "2020-06-26T00:10:28.571852Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_xgboost.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:14:13.298092Z",
     "start_time": "2020-06-26T00:14:13.293652Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_xgboost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T00:14:52.670690Z",
     "start_time": "2020-06-26T00:14:51.780647Z"
    }
   },
   "outputs": [],
   "source": [
    "xgbc_clf = XGBClassifier(scale_pos_weight=.96, learning_rate = 0.1, max_depth = 3, n_estimators = 180)\n",
    "xgbc_clf.fit(X_train_tfidf, y_train)\n",
    "y_test_preds = xgbc_clf.predict(X_test_tfidf)\n",
    "y_train_preds = xgbc_clf.predict(X_train_tfidf)\n",
    "print(classification_report(y_test, y_test_preds))\n",
    "print(confusion_matrix(y_test, y_test_preds))\n",
    "print(\"Test SVM Accuracy Score -> \",accuracy_score(y_test, y_test_preds)*100)\n",
    "print(\"Training SVM Accuracy Score -> \",accuracy_score(y_train, y_train_preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
